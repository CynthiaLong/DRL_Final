agent: Mixed_CatDqnAgent
agent_params:
  n_atoms: 51
algo: Mixed_CategoricalDQN
algo_params:
  ReplayBufferCls: PrioritizedReplayBuffer
  V_max: 70
  V_min: -90
  batch_size: 512
  clf_learning_rate: null
  clf_loss_complete_data_flag: false
  clf_loss_flag: true
  clf_loss_func: sigmoid_modulated_cross_entropy_and_entropy_loss
  clf_loss_kwargs:
    alpha: 50
    ent_weight: 0.0
    max_turns: 30
    use_severity_as_weight: false
  clf_loss_only_at_end_episode_flag: true
  clf_reward_coef: 1.0
  clf_reward_flag: true
  clf_reward_func: sigmoid_modulated_cross_entropy_and_entropy_neg_reward
  clf_reward_kwargs:
    alpha: 50
    ce_max_value: 30.0
    ce_weight: 1.0
    ent_max_value: null
    ent_weight: 0.0
    exit_loss_coeff: 1.0
    initial_penalty: 0.0
    max_turns: 30
    penalty_alpha: 50
    reverse_entropy_reward_flag: false
    reverse_reward_flag: true
    sev_f1_weight: 0.0
    sev_in_weight: 1.0
    sev_out_weight: 0.0
    should_zero_centered_ce: true
    use_severity_as_weight: false
  clf_reward_max: null
  clf_reward_min: null
  discount: 0.99
  double_dqn: true
  env_reward_coef: 1.0
  eps_steps: 4000000
  learning_rate: 6.25e-05
  min_steps_learn: 500000
  n_step_return: 3
  pretrain_batch_size: 1000
  pretrain_clf_learning_rate: 0.0001
  pretrain_epochs: 100
  pretrain_flag: false
  pretrain_loss_func: cross_entropy
  pretrain_loss_kwargs: {}
  pretrain_perf_metric: null
  pretrain_validation_percentage: 0.25
  prioritized_replay: true
  replay_intermediate_data_flag: true
  replay_ratio: 32
  replay_size: 4000000
  reward_shaping_back_propagate_flag: false
  reward_shaping_coef: 1.0
  reward_shaping_flag: true
  reward_shaping_func: ce_ent_sent_reshaping
  reward_shaping_kwargs:
    bounds_dict:
      ce_max: 2
      ce_min: -2
      js_max: 0.25
      js_min: 0
      sev_out_max: 2
      sev_out_min: -3.5
    ce_alpha: 4
    ce_weight: 1
    ent_alpha: 9
    ent_weight: 0.0
    js_alpha: 9
    js_weight: 12
    link_div_with_negative_evidence: false
    max_map_val: 13.0
    max_turns: 30
    min_map_val: -13.0
    normalize_sev_dist: false
    reverse_ce_flag: false
    reverse_flag: false
    sev_ent_alpha: 8
    sev_ent_alpha_b: 0.5
    sev_ent_weight: 0.0
    sev_f1_alpha: -50
    sev_f1_weight: 0.0
    sev_in_alpha: -50
    sev_in_weight: 0.0
    sev_js_weight: 0.0
    sev_out_alpha: -50
    sev_out_weight: 0.75
    sev_tv_weight: 0.0
    tv_alpha: 5
    tv_weight: 0.0
  reward_shaping_max: null
  reward_shaping_min: null
  separate_classifier_optimizer: true
  target_update_interval: 100
architecture: mixed_cat_dqn_model
architecture_params:
  dueling: true
  dueling_fc_sizes:
  - 1024
  - 512
  embedding_dict:
    1: 8
    2: 2
  freeze_one_hot_encoding: true
  hidden_sizes:
  - 4096
  - 2048
  - 2048
  include_turns_in_state: true
  input_size: 915
  mask_inquired_symptoms: true
  min_turns_ratio_for_decision: null
  n_atoms: null
  not_inquired_value: 0
  num_symptoms: 223
  output_size: 272
  pi_hidden_sizes:
  - 1024
  - 512
  use_stop_action: true
  use_turn_just_for_masking: false
config_uid: 0910b2277dc74b8d87e124c89ede158c
eval_max_steps: 4000
eval_max_trajectories: 100
eval_metrics:
- accuracy
- f1
- top-1-accuracy
- top-2-accuracy
- top-3-accuracy
- top-5-accuracy
eval_n_envs: 0
exp_name: MainResultConfig
experiment_folder: ./output/config1/MainResultConfig/0910b2277dc74b8d87e124c89ede158c
log_interval_steps: 200000
max_decorrelation_steps: 400
mlflow_uid: 0910b2277dc74b8d87e124c89ede158c
n_envs: 16
n_steps: 100000000
optimizer: adam
optimizer_params:
  eps: 0.00015
patience: 81
perf_metric: MainPerformanceMetric
perf_window_size: 10
reward_config:
  reward_on_correct_diagnosis: 0
  reward_on_intermediary_turns: -0.5
  reward_on_irrelevant_symptom_inquiry: 0.0
  reward_on_missing_diagnosis: 0
  reward_on_relevant_symptom_inquiry: 2
  reward_on_repeated_action: 0
runner: MinibatchRl
runner_params:
  custom_metrics:
    MainPerformanceMetric:
      AUCTraj: 0.25
      DDF1: 0.5
      PER: 0.25
    SecondPerformanceMetric:
      AUCTraj: 0.25
      DDF1: 0.25
      DSF1: 0.25
      PER: 0.25
    ThirdPerformanceMetric:
      DDF1: 0.25
      DSF1: 0.5
      PER: 0.25
  eval_coeffs:
  - 0.5
  - 0.25
  - 0.15
  - 0.1
  seed: 3834
  topk: 5
  traj_auxiliary_reward_flag: false
sampler: GpuSampler
sampler_params: {}
simulator_params:
  action_type: 0
  condition_filepath: ./data/release_conditions.json
  include_ethnicity_in_state: false
  include_race_in_state: false
  include_turns_in_state: true
  is_reward_relevancy_patient_specific: true
  max_turns: 30
  stop_if_repeated_question: false
  symptom_filepath: ./data/release_evidences.json
  use_differential_diagnosis: true
